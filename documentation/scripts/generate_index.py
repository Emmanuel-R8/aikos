#!/usr/bin/env python3
"""
Generate autogenerated index for Typst documentation.
Extracts terms, glossary entries, functions, opcodes, and concepts.
"""

import re
from pathlib import Path
from typing import Dict, List, Set
from collections import defaultdict

def extract_headings(content: str) -> List[tuple]:
    """Extract all headings with their levels and text."""
    headings = []
    for line in content.split('\n'):
        # Typst headings: =, ==, ===, etc.
        match = re.match(r'^(=+)\s+(.+)$', line)
        if match:
            level = len(match.group(1))
            text = match.group(2).strip()
            headings.append((level, text))
    return headings

def extract_code_blocks(content: str) -> List[str]:
    """Extract function names and opcodes from code blocks."""
    functions = []
    opcodes = []
    
    # Extract from codeblock
    code_pattern = r'#codeblock\([^)]+\)\s*\[(.*?)\]'
    for match in re.finditer(code_pattern, content, re.DOTALL):
        code = match.group(1)
        
        # Function definitions
        func_matches = re.findall(r'\bfunction\s+(\w+)', code)
        functions.extend(func_matches)
        
        # Function calls
        call_matches = re.findall(r'(\w+)\s*\(', code)
        functions.extend(call_matches)
        
        # Opcodes (OP_*)
        opcode_matches = re.findall(r'OP_(\w+)', code)
        opcodes.extend(opcode_matches)
    
    return functions, opcodes

def extract_glossary_terms(content: str) -> List[str]:
    """Extract glossary terms (=== headings in glossary section)."""
    terms = []
    in_glossary = False
    
    for line in content.split('\n'):
        if '= Glossary' in line or '== Glossary' in line:
            in_glossary = True
        elif in_glossary and line.startswith('==='):
            term = line.replace('===', '').strip()
            if term:
                terms.append(term)
        elif in_glossary and line.startswith('==') and not line.startswith('==='):
            # New section, might not be glossary anymore
            if 'Glossary' not in line:
                break
    
    return terms

def extract_concepts(content: str) -> List[str]:
    """Extract key concepts (bold text, important terms)."""
    concepts = set()
    
    # Bold text (might be concepts)
    bold_pattern = r'\*([^*]+)\*'
    for match in re.finditer(bold_pattern, content):
        text = match.group(1).strip()
        # Filter out common words
        if len(text) > 3 and text[0].isupper():
            concepts.add(text)
    
    # Code/type references
    code_pattern = r'`([^`]+)`'
    for match in re.finditer(code_pattern, content):
        text = match.group(1).strip()
        if len(text) > 2:
            concepts.add(text)
    
    return sorted(concepts)

def extract_opcodes_from_content(content: str) -> List[str]:
    """Extract opcode names from content."""
    opcodes = set()
    
    # OP_* patterns
    opcode_pattern = r'OP_(\w+)'
    for match in re.finditer(opcode_pattern, content):
        opcodes.add(match.group(1))
    
    # Opcode references in text
    opcode_ref_pattern = r'opcode[s]?\s+(\w+)'
    for match in re.finditer(opcode_ref_pattern, content, re.IGNORECASE):
        opcodes.add(match.group(1))
    
    return sorted(opcodes)

def process_file(typ_path: Path) -> Dict:
    """Process a Typst file and extract indexable content."""
    with open(typ_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    result = {
        'file': str(typ_path.relative_to(Path('documentation'))),
        'headings': extract_headings(content),
        'functions': [],
        'opcodes': [],
        'terms': [],
        'concepts': []
    }
    
    # Extract from code blocks
    funcs, opcs = extract_code_blocks(content)
    result['functions'] = sorted(set(funcs))
    result['opcodes'].extend(opcs)
    
    # Extract opcodes
    opcs = extract_opcodes_from_content(content)
    result['opcodes'].extend(opcs)
    result['opcodes'] = sorted(set(result['opcodes']))
    
    # Extract glossary terms if this is glossary file
    if 'glossary' in typ_path.name.lower():
        result['terms'] = extract_glossary_terms(content)
    
    # Extract concepts
    result['concepts'] = extract_concepts(content)
    
    return result

def generate_index_typ(all_data: List[Dict]) -> str:
    """Generate Typst index file."""
    lines = ['= Index\n']
    lines.append('Autogenerated index of terms, concepts, functions, and opcodes.\n\n')
    
    # Collect all items by category
    all_terms = defaultdict(set)
    all_functions = defaultdict(set)
    all_opcodes = defaultdict(set)
    all_concepts = defaultdict(set)
    
    for data in all_data:
        file_ref = data['file'].replace('.typ', '')
        for term in data['terms']:
            all_terms[term].add(file_ref)
        for func in data['functions']:
            if func and len(func) > 2:  # Filter out very short names
                all_functions[func].add(file_ref)
        for opcode in data['opcodes']:
            if opcode:
                all_opcodes[opcode].add(file_ref)
        for concept in data['concepts']:
            if concept and len(concept) > 2:
                all_concepts[concept].add(file_ref)
    
    # Generate index sections
    if all_terms:
        lines.append('== Terms\n\n')
        for term in sorted(all_terms.keys()):
            files = sorted(all_terms[term])
            lines.append(f'- *{term}*: {", ".join(files[:3])}' + (' ...' if len(files) > 3 else '') + '\n')
        lines.append('\n')
    
    if all_functions:
        lines.append('== Functions\n\n')
        for func in sorted(all_functions.keys())[:200]:  # Limit to first 200
            files = sorted(all_functions[func])
            lines.append(f'- `{func}()`: {", ".join(files[:2])}' + (' ...' if len(files) > 2 else '') + '\n')
        lines.append('\n')
    
    if all_opcodes:
        lines.append('== Opcodes\n\n')
        for opcode in sorted(all_opcodes.keys()):
            files = sorted(all_opcodes[opcode])
            lines.append(f'- `OP_{opcode}`: {", ".join(files[:2])}' + (' ...' if len(files) > 2 else '') + '\n')
        lines.append('\n')
    
    if all_concepts:
        lines.append('== Concepts\n\n')
        # Limit concepts to most important ones
        important_concepts = sorted(all_concepts.keys())[:150]
        for concept in important_concepts:
            files = sorted(all_concepts[concept])
            lines.append(f'- *{concept}*: {", ".join(files[:2])}' + (' ...' if len(files) > 2 else '') + '\n')
        lines.append('\n')
    
    return ''.join(lines)

def main():
    """Main function."""
    doc_dir = Path('documentation')
    typ_files = list(doc_dir.rglob('*.typ'))
    
    print(f"Processing {len(typ_files)} Typst files...")
    
    all_data = []
    for typ_path in typ_files:
        if 'index.typ' in str(typ_path) or 'main.typ' in str(typ_path):
            continue
        try:
            data = process_file(typ_path)
            all_data.append(data)
        except Exception as e:
            print(f"Error processing {typ_path}: {e}")
    
    # Generate index
    index_content = generate_index_typ(all_data)
    
    # Write index file
    index_path = doc_dir / 'reference' / 'index.typ'
    index_path.parent.mkdir(parents=True, exist_ok=True)
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(index_content)
    
    print(f"Index generated: {index_path}")
    print(f"Indexed {len(all_data)} files")

if __name__ == '__main__':
    main()
